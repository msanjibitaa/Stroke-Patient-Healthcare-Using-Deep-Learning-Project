{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2625921860.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    <br> <br> \\# Load dataset \\# This line loads the dataset into a pandas\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Importing required library\n",
    "\n",
    "# We import the pandas library to leverage its powerful data manipulation and analysis capabilities.\n",
    "\n",
    "import pandas as pd  \n",
    "<br> <br> \\# Load dataset \\# This line loads the dataset into a pandas\n",
    "DataFrame. The dataset is assumed to be in CSV format. df =\n",
    "pd.read_csv(‘dataset/data.csv’)  \n",
    "<br><br> \\# Data Exploration\n",
    "\n",
    "## 1. Basic Exploration\n",
    "\n",
    "### Basic statistical description of numerical data:\n",
    "\n",
    "# We generate descriptive statistics for numerical columns to understand the data’s distribution, central tendencies, and variability.\n",
    "\n",
    "print(df.describe()) print(“Basic statistical description of numerical\n",
    "data:”)  \n",
    "<br><br> \\### Dataset information (columns, types, and non-null counts):\n",
    "\\# This provides an overview of the DataFrame’s structure, including the\n",
    "data types and the number of non-null entries, which helps identify\n",
    "potential data issues. print(“information (columns, types, and non-null\n",
    "counts):”)  \n",
    "print(df.info()) <br><br> \\### Shape of the dataset (rows, columns): \\#\n",
    "Knowing the dimensions of the dataset is crucial for understanding its\n",
    "size and the complexity of any analyses we plan to perform. print(“of\n",
    "the dataset (rows, columns):”)  \n",
    "print(df.shape) <br><br> \\### Basic statistical description of\n",
    "categorical data: \\# This step gives insight into categorical variables,\n",
    "revealing the number of unique entries and their frequency, which aids\n",
    "in understanding the dataset’s categorical distribution.\n",
    "print(“statistical description of categorical data:”)  \n",
    "print(df.describe(include=‘object’)) <br><br> \\## 2. Unique Value and\n",
    "Null Value Analysis\n",
    "\n",
    "### Unique values in ‘gender’ column:\n",
    "\n",
    "# Identifying unique values in categorical columns like ‘gender’ is important for understanding the diversity of the dataset and ensuring the data is clean.\n",
    "\n",
    "print(“values in ‘gender’ column:”)  \n",
    "gender_unique = df\\[‘gender’\\].unique() <br><br> \\### Unique values in\n",
    "‘smoking_status’ column: \\# Similarly, checking for unique values in\n",
    "‘smoking_status’ helps us ensure that the data is properly categorized\n",
    "and identify any potential outliers or errors. print(“values in\n",
    "‘smoking_status’ column:”)  \n",
    "smoking_status_unique = df\\[‘smoking_status’\\].unique() <br><br> \\###\n",
    "Check for null values in the dataset: \\# Understanding the presence of\n",
    "null values is critical because missing data can skew analysis and lead\n",
    "to misleading conclusions. null_values = df.isnull().sum()  \n",
    "print(“values in each column:”)  \n",
    "print(null_values) <br><br> \\### Percentage of null values in each\n",
    "column: \\# Calculating the percentage of nulls helps prioritize which\n",
    "columns need attention based on the extent of missing data.\n",
    "null_percentage = df.isnull().mean() \\* 100  \n",
    "print(“of null values in each column:”)  \n",
    "print(null_percentage)  \n",
    "<br><br> \\## 3. Observations\n",
    "\n",
    "### Observation 1: Dataset dimensions\n",
    "\n",
    "# Reporting the dimensions helps contextualize the size of the dataset for analysis.\n",
    "\n",
    "print(f”1. The dataset contains {df.shape\\[0\\]} rows and {df.shape\\[1\\]}\n",
    "columns.”) <br><br> \\### Observation 2: Missing values in ‘bmi’ column\n",
    "\\# Reporting missing values specifically for ‘bmi’ highlights potential\n",
    "issues in this critical health metric. missing_bmi_count =\n",
    "null_values\\[‘bmi’\\]  \n",
    "if missing_bmi_count \\> 0: print(f”2. The ‘bmi’ column originally\n",
    "contained {missing_bmi_count} missing values.”)  \n",
    "else: print(“2. The ‘bmi’ column contains no missing values.”)  \n",
    "<br><br> \\### Observation 3: Unique values in ‘gender’ column \\# This\n",
    "observation confirms the diversity of gender representation in the\n",
    "dataset. print(f”3. The ‘gender’ column contains the following unique\n",
    "values: {gender_unique}“) <br><br> \\### Observation 4: Unique values in\n",
    "‘smoking_status’ column \\# Understanding the unique smoking statuses can\n",
    "be crucial for health-related analysis. print(f”4. The ‘smoking_status’\n",
    "column contains the following unique values: {smoking_status_unique}“)\n",
    "<br><br> \\### Observation 5: Missing data analysis \\# This highlights\n",
    "columns needing imputation or cleaning, ensuring a more robust analysis.\n",
    "print(f”5. The dataset contains missing data in the following columns\n",
    "(with percentages):“)  \n",
    "print(null_percentage\\[null_percentage \\> 0\\])  \n",
    "<br><br> \\## 4. Handling Missing Values in ‘bmi’ Column\n",
    "\n",
    "### Option 1: Dropping rows with missing ‘bmi’ values\n",
    "\n",
    "# This option can simplify analysis but may result in loss of potentially valuable data.\n",
    "\n",
    "df_dropped = df.dropna(subset=\\[‘bmi’\\])  \n",
    "print(f”6. After dropping rows with missing ‘bmi’ values, the dataset\n",
    "contains {df_dropped.shape\\[0\\]} rows.”)  \n",
    "<br><br> \\### Option 2: Imputing missing ‘bmi’ values with the mean \\#\n",
    "Imputing with the mean retains all data points, which is often\n",
    "preferred, especially if missingness is minimal. mean_bmi =\n",
    "df\\[‘bmi’\\].mean()  \n",
    "df\\[‘bmi’\\].fillna(mean_bmi, inplace=True)  \n",
    "print(f”missing ‘bmi’ values with mean value: {mean_bmi}“) <br><br> \\###\n",
    "Check null values after imputation \\# Confirming the success of\n",
    "imputation is crucial to ensure that our data is now complete.\n",
    "null_values_after = df.isnull().sum()  \n",
    "print(”values after imputing missing ‘bmi’ values:“)  \n",
    "print(null_values_after) <br><br> \\### Observation 7: No missing values\n",
    "in ‘bmi’ column after imputation \\# This final confirmation ensures we\n",
    "can proceed confidently with analysis. if null_values_after\\[‘bmi’\\] ==\n",
    "0: print(”7. After imputing, the ‘bmi’ column has no missing values.”)  \n",
    "<br><br> \\## 5. Duplicate Rows Check \\### Identify duplicate rows in the\n",
    "dataset: \\# Identifying duplicates is vital for data integrity;\n",
    "duplicates can distort analysis results. duplicates =\n",
    "df.duplicated().sum()  \n",
    "print(f”of duplicate rows: {duplicates}“) <br><br> \\## 6. Stroke Rate\n",
    "Analysis\n",
    "\n",
    "### Stroke rate by gender:\n",
    "\n",
    "# Analyzing stroke rates by gender helps uncover potential health disparities and informs targeted health interventions.\n",
    "\n",
    "print(“rate by gender:”)  \n",
    "print(df.groupby(‘gender’)\\[‘stroke’\\].mean()) <br><br> \\# Observation\n",
    "of stroke rate by gender: \\# gender \\# Female 0.047094 \\# Male 0.051064\n",
    "\\# Other 0.000000 <br><br> \\### Stroke percentage by gender (relative to\n",
    "all stroke cases): total = df\\[‘stroke’\\].sum()  \n",
    "strokes_gender = df\\[df\\[‘stroke’\\] ==\n",
    "1\\].groupby(‘gender’)\\[‘stroke’\\].count()  \n",
    "stroke_per = (strokes_gender / total) \\* 100  \n",
    "print(“percentage by gender (relative to all stroke cases):”)  \n",
    "print(stroke_per) \\# Understanding the proportion of strokes by gender\n",
    "is essential for evaluating the impact of gender on stroke incidence.\n",
    "<br><br> \\# Output of stroke percentage: \\# gender \\# Female 56.626506\n",
    "\\# Male 43.373494"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
